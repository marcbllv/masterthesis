@inproceedings{lime,
    author = {Ribeiro, M. T. and Singh, S. and Guestrin, C.},
    title  = {Why Should I Trust You? Explaining the Predictions of Any Classifier},
    series = {KDD '16},
    year   = {2016},
    url    = {http://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf},
}

@misc{limeGitHub,
  author = {Ribeiro, M. T. },
  title = {Lime},
  year = {2016},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/marcotcr/lime}}
}

@article{mythos,
  author    = {Zachary Chase Lipton},
  title     = {The Mythos of Model Interpretability},
  journal   = {CoRR},
  volume    = {abs/1606.03490},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.03490},
  timestamp = {Fri, 01 Jul 2016 17:39:49 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/Lipton16a},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@article{explvect,
    title   = {How to Explain Individual Classification Decisions},
    author  = {Baehrens, D. and Schroeter, T. and Harmeling, S.},
    journal = {Journal of Machine Learning Research},
    volume  = {11},
    year    = {2010},
    pages   = {1803-1831}
}

@article{gametheory,
    title   = "An Efficient Explanation of Individual Classifications using Game Theory",
    author  = "Strumbelj, E. and Kononenko, I",
    journal = {Journal of Machine Learning Research},
    volume  = {11},
    year    = {2010},
    pages   = {1-18}
}

@article{treeinterpreter,
    title   = {Interpreting random forests},
    url = {http://blog.datadive.net/interpreting-random-forests/},
    author  = {Saba, A.},
    journal = {Diving into data},
    year    = {2015}
}

@unpublished{euregulation,
    title   = {European Union regulations on algorithmic decision-making and a “right to explanation”},
    url = {https://arxiv.org/pdf/1606.08813v3.pdf},
    author  = {Goodman, B. and Flaxman, S.},
    year    = {2016}
}

@inproceedings{healthcare,
    title   = {Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission},
    author  = {Caruana, R. and Lou, Y. and Gehrke, J. and Koch, P. and Sturm, M.},
    series  = {KDD '15},
    year    = {2015},
    pages   = {1721-1730}
}

@article{trust,
    title   = {The role of trust in automation reliance},
    author  = {Mary T. Dzindoleta and Scott A. Petersona and Regina A. Pomrankyb and Linda G. Pierceb and Hall P. Beck},
    journal = {International Journal of Human-Computer Studies},
    volume  = {58},
    year    = {2003},
    pages   = {697-718}
}

@article{documentclassif,
    title   = {Explaining data-driven document classifications},
    author  = {Martens, D. and Provost, F.},
    journal = {MIS Quarterly},
    volume  = {38},
    year    = {2014},
    month   = {March},
    pages   = {73-100}
}

@article{explainingclassif,
    title   = {Explaining Classifications For Individual Instances},
    author  = {Konenko, I. and Robnik-Šikonja},
    journal = {IEEE Transactions on Knowledge \& Data Engineering},
    volume  = {20},
    year    = {2008},
    month   = {May},
    pages   = {589-600}
}

@article{ice,
    title   = {Peeking Inside the Black Box: Visualizing Statistical
               Learning With Plots of Individual Conditional Expectation},
    author  = {Alex Goldstein and Adam Kapelner and Justin Bleich and
               Emil Pitkin},
    journal = {Journal of Computational and Graphical Statistics},
    volume  = {24},
    number  = {1},
    pages   = {44--65},
    doi     = {10.1080/10618600.2014.907095},
    year    = {2015}
}

@article{evolutionnary,
	title = {An evolutionary approach for automatically extracting intelligible classification rules},
	author = {De Falco, I. and Della Ciopa, A. and Iazzetta, A. and Tarantino, E.},
	journal = {Journal of Knowledge and Information Systems},
	volume = {7},
	number = {2},
	month = {February},
	year = {2015},
	pages = {179--201},
	doi = {10.1007/s10115-003-0143-4}
}

@book{interpretingusing,
    author    = {Christopher H. Achen},
    title     = {Interpreting and using regression},
    publisher = {SAGE},
    year = {1982},
    month = {October}
}

@article{breastcancer,
	title = {Explanation and reliability of prediction models: the case of breast cancer recurrence},
	author = {Štrumbelj, E. and Bosnić, Z. and Kononenko, I. and Zakotnik, B. and Grašič Kuhar, C.},
	journal = {Journal of Knowledge and Information Systems},
	volume = {7},
	number = {2},
	month = {August},
	year = {2010},
	pages = {305--324}
}

@article{sensitivity,
	title = {Estimation of individual prediction reliability using the local sensitivity analysis},
	author = {Bosnić, Z. and Kononenko, I.},
	journal = {Journal of Applied Intelligence},
	volume = {29},
	number = {3},
	month = {August},
	year = {2007},
	pages = {187--203},
	doi = {10.1007/s10489-007-0084-9}
}

@inproceedings{bansal2014towards,
  title={Towards transparent systems: Semantic characterization of failure modes},
  author={Bansal, Aayush and Farhadi, Ali and Parikh, Devi},
  booktitle={European Conference on Computer Vision},
  pages={366--381},
  year={2014},
  organization={Springer}
}

@Article{Breiman2001,
author="Breiman, Leo",
title="Random Forests",
journal="Machine Learning",
year="2001",
volume="45",
number="1",
pages="5--32",
abstract="Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund {\&} R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148--156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.",
issn="1573-0565",
doi="10.1023/A:1010933404324",
url="http://dx.doi.org/10.1023/A:1010933404324"
}

@article{Friedman2001,
 ISSN = {00905364},
 URL = {http://www.jstor.org/stable/2699986},
 abstract = {Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent "boosting" paradigm is developed for additive expansions based on any fitting criterion. Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such "TreeBoost" models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.},
 author = {Jerome H. Friedman},
 journal = {The Annals of Statistics},
 number = {5},
 pages = {1189-1232},
 publisher = {Institute of Mathematical Statistics},
 title = {Greedy Function Approximation: A Gradient Boosting Machine},
 volume = {29},
 year = {2001}
}

@inproceedings{Vapnik1992,
  added-at = {2009-05-16T10:01:31.000+0200},
  author = {Boser, Bernhard E. and Guyon, Isabelle and Vapnik, Vladimir},
  biburl = {http://www.bibsonomy.org/bibtex/27760ca3eab90ebf595d3118336b756b9/hkorte},
  booktitle = {Computational Learing Theory },
  interhash = {81c1ca02cfdb4006d4ae602fcbbafcd3},
  intrahash = {7760ca3eab90ebf595d3118336b756b9},
  keywords = {svm},
  pages = {144--152 },
  timestamp = {2009-05-16T10:01:31.000+0200},
  title = {A Training Algorithm for Optimal Margin Classifiers},
  url = {http://www.svms.org/training/BOGV92.pdf},
  year = 1992
}

@book{cart,
  author        = {L. Breiman and J. Friedman and R. Olshen and C. Stone},
  title         = {Classification and Regression Trees},
  publisher     = {Wadsworth and Brooks},
  address       = {Monterey, CA},
  year          = {1984}
}

@article{rosenblatt,
author = "Rosenblatt, Murray",
doi = "10.1214/aoms/1177728190",
fjournal = "The Annals of Mathematical Statistics",
journal = "Ann. Math. Statist.",
month = "09",
number = "3",
pages = "832--837",
publisher = "The Institute of Mathematical Statistics",
title = "Remarks on Some Nonparametric Estimates of a Density Function",
url = "http://dx.doi.org/10.1214/aoms/1177728190",
volume = "27",
year = "1956"
}

@article{parzen,
author = "Parzen, Emanuel",
doi = "10.1214/aoms/1177704472",
fjournal = "The Annals of Mathematical Statistics",
journal = "Ann. Math. Statist.",
month = "09",
number = "3",
pages = "1065--1076",
publisher = "The Institute of Mathematical Statistics",
title = "On Estimation of a Probability Density Function and Mode",
url = "http://dx.doi.org/10.1214/aoms/1177704472",
volume = "33",
year = "1962"
}

@book{elementsofstats,
   title = "The elements of statistical learning : data mining, inference, and prediction",
   author = "Hastie, Trevor J. and Tibshirani, Robert John and Friedman, Jerome H.",
   series = "Springer series in statistics",
   publisher = "Springer",
   address = "New York",
   url = "http://opac.inria.fr/record=b1127878",
   isbn = "978-0-387-84857-0",
   note = "Autres impressions : 2011 (corr.), 2013 (7e corr.)",
   year = 2009
}

@article{shapleyvalue,
  title={A value for n-person games},
  author={Shapley, Lloyd S},
  journal={Contributions to the Theory of Games},
  volume={2},
  number={28},
  pages={307--317},
  year={1953}
}

@incollection{hart1989shapley,
  title={Shapley value},
  author={Hart, Sergiu},
  booktitle={Game Theory},
  pages={210--216},
  year={1989},
  publisher={Springer}
}

